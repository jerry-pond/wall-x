# WALL-X Docker éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU (è®¡ç®—èƒ½åŠ› 7.5+)
  - å• GPU è®­ç»ƒ: 48GB+ VRAM (RTX 6000 Ada, A6000)
  - å¤š GPU è®­ç»ƒ: 8x GPU æ¨è (å¯ç”¨ FSDP2)
- **å†…å­˜**: 64GB+ ç³»ç»Ÿå†…å­˜
- **å­˜å‚¨**: 100GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 22.04 / 20.04 / RHEL 8+
- **Docker**: 24.0+
- **NVIDIA Driver**: 535+ (æ”¯æŒ CUDA 12.4)
- **nvidia-docker2** æˆ– **NVIDIA Container Toolkit**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£… NVIDIA Container Toolkit

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

### 2. éªŒè¯ GPU è®¿é—®

```bash
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

### 3. æ„å»º Docker é•œåƒ

```bash
# å…‹éš†ä»“åº“
git clone <your-wall-x-repo>
cd wall-x

# æ„å»ºé•œåƒ (éœ€è¦ 20-30 åˆ†é’Ÿ)
docker build -t wall-x:latest .

# æˆ–ä½¿ç”¨ docker-compose
docker-compose build
```

### 4. å‡†å¤‡æ•°æ®å’Œæ¨¡å‹

```bash
# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p workspace data checkpoints

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ (é€‰æ‹©ä¸€ä¸ª)
# WALL-OSS-FLOW
git clone https://huggingface.co/x-square-robot/wall-oss-flow ./checkpoints/wall-oss-flow

# WALL-OSS-FAST
git clone https://huggingface.co/x-square-robot/wall-oss-fast ./checkpoints/wall-oss-fast

# (å¯é€‰) ä¸‹è½½ FAST tokenizer
git clone https://huggingface.co/physical-intelligence/fast ./checkpoints/fast
```

### 5. å¯åŠ¨å®¹å™¨

#### æ–¹æ³• A: ä½¿ç”¨ docker-compose (æ¨è)

```bash
docker-compose up -d
docker-compose exec wall-x bash
```

#### æ–¹æ³• B: ä½¿ç”¨ docker run

```bash
docker run -it --rm \
  --gpus all \
  --shm-size=32g \
  --ipc=host \
  -v $(pwd)/workspace:/workspace/wall-x/workspace \
  -v $(pwd)/data:/workspace/wall-x/data \
  -v $(pwd)/checkpoints:/workspace/wall-x/checkpoints \
  -v ~/.cache/huggingface:/root/.cache/huggingface \
  wall-x:latest
```

## ğŸ”§ é…ç½®è®­ç»ƒ

### 1. æ›´æ–°é…ç½®æ–‡ä»¶

åœ¨å®¹å™¨å†…ä¿®æ”¹é…ç½®:

```bash
cd /workspace/wall-x/workspace/lerobot_example
vim config_qact.yml
```

å¿…é¡»ä¿®æ”¹çš„è·¯å¾„:
```yaml
pretrained_wallx_path: "/workspace/wall-x/checkpoints/wall-oss-flow"
save_path: "/workspace/wall-x/workspace/outputs"
use_fast_tokenizer: false
action_tokenizer_path: "/workspace/wall-x/checkpoints/fast"  # å¦‚ä½¿ç”¨ FAST
```

### 2. æ›´æ–°è¿è¡Œè„šæœ¬

```bash
vim run.sh
```

è®¾ç½®æ­£ç¡®çš„è·¯å¾„:
```bash
code_dir="/workspace/wall-x"
config_path="/workspace/wall-x/workspace/lerobot_example/config_qact.yml"
```

### 3. å¯åŠ¨è®­ç»ƒ

```bash
# åœ¨å®¹å™¨å†…æ‰§è¡Œ
source activate wallx
bash ./run.sh
```

## ğŸ“Š GPU ä½¿ç”¨å»ºè®®

### å• GPU (48GB+ VRAM)
```bash
CUDA_VISIBLE_DEVICES=0 bash run.sh
```

é…ç½®:
```yaml
batch_size_per_gpu: 1
FSDP2: false
torch_compile: false
```

### å¤š GPU (8x GPU, æ¨è)
```bash
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 bash run.sh
```

é…ç½®:
```yaml
batch_size_per_gpu: 1
FSDP2: true
torch_compile: false  # é™¤éç¡®ä¿æ•°æ®å½¢çŠ¶ä¸€è‡´
```

## ğŸ§ª æµ‹è¯•æ¨ç†

### 1. åŸºç¡€åŠ¨ä½œæ¨ç†

```bash
source activate wallx
python ./scripts/fake_inference.py
```

### 2. å¼€ç¯è¯„ä¼°

```bash
python ./scripts/draw_openloop_plot.py
```

### 3. VQA å’Œæ€ç»´é“¾æµ‹è¯•

```bash
python ./scripts/vqa_inference.py
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA å†…å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**:
- å‡å° `batch_size_per_gpu`
- å¯ç”¨ FSDP2 (å¤š GPU)
- å¢åŠ  `gradient_accumulation_steps`

### Q2: Flash-Attention ç¼–è¯‘å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**:
```bash
# åœ¨ Dockerfile ä¸­è°ƒæ•´ MAX_JOBS
ENV MAX_JOBS=2  # é™ä½å¹¶è¡Œç¼–è¯‘æ•°
```

### Q3: CUDA ç‰ˆæœ¬ä¸åŒ¹é…
**æ£€æŸ¥**:
```bash
nvidia-smi  # æŸ¥çœ‹é©±åŠ¨æ”¯æŒçš„ CUDA ç‰ˆæœ¬
nvcc --version  # æŸ¥çœ‹å®¹å™¨å†… CUDA ç‰ˆæœ¬
```

### Q4: å®¹å™¨å†…æ— æ³•è®¿é—® GPU
**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿å®‰è£…äº† nvidia-docker2
docker run --rm --gpus all nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi

# é‡å¯ Docker æœåŠ¡
sudo systemctl restart docker
```

## ğŸ“¦ æ•°æ®æŒä¹…åŒ–

å®¹å™¨ä½¿ç”¨å·æŒ‚è½½ä¿æŒæ•°æ®æŒä¹…åŒ–:

```bash
å®¿ä¸»æœº                          â†’ å®¹å™¨å†…
./workspace                     â†’ /workspace/wall-x/workspace
./data                          â†’ /workspace/wall-x/data
./checkpoints                   â†’ /workspace/wall-x/checkpoints
~/.cache/huggingface            â†’ /root/.cache/huggingface
```

## ğŸ”„ æ›´æ–°ä»£ç 

```bash
# åœæ­¢å®¹å™¨
docker-compose down

# æ‹‰å–æœ€æ–°ä»£ç 
git pull

# é‡æ–°æ„å»ºé•œåƒ
docker-compose build

# é‡æ–°å¯åŠ¨
docker-compose up -d
```

## ğŸ“ æ—¥å¿—å’Œç›‘æ§

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
# å®æ—¶æŸ¥çœ‹
docker-compose logs -f wall-x

# æˆ–åœ¨å®¹å™¨å†…
tail -f /workspace/wall-x/workspace/outputs/training.log
```

### ç›‘æ§ GPU ä½¿ç”¨
```bash
# å®¿ä¸»æœºä¸Š
watch -n 1 nvidia-smi

# å®¹å™¨å†…
watch -n 1 nvidia-smi
```

## ğŸ› ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰ CUDA æ¶æ„

ä¿®æ”¹ Dockerfile:
```dockerfile
ENV TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0"  # æ ¹æ®ä½ çš„ GPU
```

### ä½¿ç”¨å¤šèŠ‚ç‚¹è®­ç»ƒ

éœ€è¦é…ç½® Docker Swarm æˆ– Kubernetesã€‚å‚è€ƒ PyTorch åˆ†å¸ƒå¼è®­ç»ƒæ–‡æ¡£ã€‚

### å¼€å‘æ¨¡å¼

æŒ‚è½½æºä»£ç ä»¥ä¾¿å®æ—¶ä¿®æ”¹:
```bash
docker run -it --rm \
  --gpus all \
  -v $(pwd):/workspace/wall-x \
  wall-x:latest
```

## ğŸ“š å‚è€ƒèµ„æº

- [NVIDIA Container Toolkit æ–‡æ¡£](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [Docker GPU æ”¯æŒ](https://docs.docker.com/config/containers/resource_constraints/#gpu)
- [PyTorch Docker é•œåƒ](https://hub.docker.com/r/pytorch/pytorch)
- [WALL-X é¡¹ç›®ä¸»é¡µ](https://x2robot.com/en/research/68bc2cde8497d7f238dde690)